{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import tensorflow as tf\n",
    "\n"
   ],
   "metadata": {
    "id": "49qMhOK0TsWy"
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data_train = pd.read_csv(\"train_dataset_train.csv\")"
   ],
   "metadata": {
    "id": "z19212SqaKSR"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data_train.head(3)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "9ds4vb34acCX",
    "outputId": "9e2a09b9-855f-4033-a683-8ee1422d7b7d"
   },
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "        id      Easting      Northing   Height  Reflectance  Class\n0  2321251  431696.5375  6.032319e+06  69.2226       -11.14      0\n1  3515173  431710.3835  6.032291e+06  68.9711       -15.16      3\n2  2320295  431696.8099  6.032322e+06  69.2453       -13.59      0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>Easting</th>\n      <th>Northing</th>\n      <th>Height</th>\n      <th>Reflectance</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2321251</td>\n      <td>431696.5375</td>\n      <td>6.032319e+06</td>\n      <td>69.2226</td>\n      <td>-11.14</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3515173</td>\n      <td>431710.3835</td>\n      <td>6.032291e+06</td>\n      <td>68.9711</td>\n      <td>-15.16</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2320295</td>\n      <td>431696.8099</td>\n      <td>6.032322e+06</td>\n      <td>69.2453</td>\n      <td>-13.59</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "data_y = data_train[\"Class\"]\n",
    "encod_y = LabelBinarizer()\n",
    "Y_train = encod_y.fit_transform(data_y)"
   ],
   "metadata": {
    "id": "rkhgmZ-Nagy9"
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_train_dataset_x(data_x):\n",
    "\n",
    "  data_X = data_x.copy()\n",
    "  norm = MinMaxScaler()\n",
    "  pca = PCA(5)\n",
    "  res = norm.fit_transform(data_X)\n",
    "  res = pca.fit_transform(res)\n",
    "  X_train = res\n",
    "\n",
    "  return X_train, norm, pca"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def get_test_dataset_x(data_x, norm, pca):\n",
    "\n",
    "  data_X = data_x.copy()\n",
    "  res = norm.transform(data_X)\n",
    "  res = pca.transform(res)\n",
    "\n",
    "  X_test = res\n",
    "\n",
    "  return X_test"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "data_x_best = data_train[data_train.columns[:-1]]\n",
    "X_train, norm, pca = get_train_dataset_x(data_x_best)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "best_model = tf.keras.models.load_model(\"model_best.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_27 (Dense)            (None, 1000)              6000      \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1000)              1001000   \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1000)              1001000   \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 1000)              1001000   \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 1000)              1001000   \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 6)                 6006      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,016,006\n",
      "Trainable params: 4,016,006\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "best_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Recall\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "initial_learning_rate = 0.00000001\n",
    "lr_schedule = ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=1000000,\n",
    "    decay_rate=1,\n",
    "    staircase=True)\n",
    "opt = Adam(learning_rate=lr_schedule)\n",
    "met = Recall()\n",
    "best_model.compile(optimizer=opt, loss=\"categorical_crossentropy\", metrics=[met])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "105/105 - 26s - loss: 0.0173 - recall_19: 0.9929 - val_loss: 0.0291 - val_recall_19: 0.9883 - 26s/epoch - 250ms/step\n",
      "Epoch 2/100\n",
      "105/105 - 25s - loss: 0.0173 - recall_19: 0.9929 - val_loss: 0.0291 - val_recall_19: 0.9883 - 25s/epoch - 240ms/step\n",
      "Epoch 3/100\n",
      "105/105 - 25s - loss: 0.0173 - recall_19: 0.9929 - val_loss: 0.0291 - val_recall_19: 0.9883 - 25s/epoch - 240ms/step\n",
      "Epoch 4/100\n",
      "105/105 - 25s - loss: 0.0173 - recall_19: 0.9929 - val_loss: 0.0291 - val_recall_19: 0.9883 - 25s/epoch - 241ms/step\n",
      "Epoch 5/100\n",
      "105/105 - 25s - loss: 0.0173 - recall_19: 0.9929 - val_loss: 0.0291 - val_recall_19: 0.9883 - 25s/epoch - 241ms/step\n",
      "Epoch 6/100\n",
      "105/105 - 25s - loss: 0.0173 - recall_19: 0.9929 - val_loss: 0.0291 - val_recall_19: 0.9883 - 25s/epoch - 241ms/step\n",
      "Epoch 7/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9929 - val_loss: 0.0291 - val_recall_19: 0.9883 - 25s/epoch - 241ms/step\n",
      "Epoch 8/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9929 - val_loss: 0.0291 - val_recall_19: 0.9883 - 25s/epoch - 241ms/step\n",
      "Epoch 9/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9929 - val_loss: 0.0291 - val_recall_19: 0.9883 - 25s/epoch - 241ms/step\n",
      "Epoch 10/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9929 - val_loss: 0.0291 - val_recall_19: 0.9883 - 25s/epoch - 241ms/step\n",
      "Epoch 11/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9929 - val_loss: 0.0291 - val_recall_19: 0.9883 - 25s/epoch - 241ms/step\n",
      "Epoch 12/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9929 - val_loss: 0.0291 - val_recall_19: 0.9883 - 25s/epoch - 241ms/step\n",
      "Epoch 13/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9929 - val_loss: 0.0291 - val_recall_19: 0.9884 - 25s/epoch - 241ms/step\n",
      "Epoch 14/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9929 - val_loss: 0.0291 - val_recall_19: 0.9884 - 25s/epoch - 241ms/step\n",
      "Epoch 15/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9929 - val_loss: 0.0291 - val_recall_19: 0.9884 - 25s/epoch - 241ms/step\n",
      "Epoch 16/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9929 - val_loss: 0.0291 - val_recall_19: 0.9884 - 25s/epoch - 241ms/step\n",
      "Epoch 17/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9929 - val_loss: 0.0291 - val_recall_19: 0.9884 - 25s/epoch - 241ms/step\n",
      "Epoch 18/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9929 - val_loss: 0.0291 - val_recall_19: 0.9884 - 25s/epoch - 241ms/step\n",
      "Epoch 19/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9929 - val_loss: 0.0291 - val_recall_19: 0.9884 - 25s/epoch - 241ms/step\n",
      "Epoch 20/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9929 - val_loss: 0.0291 - val_recall_19: 0.9884 - 25s/epoch - 241ms/step\n",
      "Epoch 21/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9929 - val_loss: 0.0291 - val_recall_19: 0.9884 - 25s/epoch - 241ms/step\n",
      "Epoch 22/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9929 - val_loss: 0.0291 - val_recall_19: 0.9884 - 25s/epoch - 241ms/step\n",
      "Epoch 23/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9929 - val_loss: 0.0291 - val_recall_19: 0.9884 - 25s/epoch - 241ms/step\n",
      "Epoch 24/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9929 - val_loss: 0.0291 - val_recall_19: 0.9884 - 25s/epoch - 241ms/step\n",
      "Epoch 25/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9929 - val_loss: 0.0291 - val_recall_19: 0.9884 - 25s/epoch - 242ms/step\n",
      "Epoch 26/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9929 - val_loss: 0.0291 - val_recall_19: 0.9884 - 25s/epoch - 242ms/step\n",
      "Epoch 27/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9929 - val_loss: 0.0291 - val_recall_19: 0.9884 - 25s/epoch - 242ms/step\n",
      "Epoch 28/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9929 - val_loss: 0.0291 - val_recall_19: 0.9884 - 25s/epoch - 242ms/step\n",
      "Epoch 29/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9929 - val_loss: 0.0291 - val_recall_19: 0.9884 - 26s/epoch - 243ms/step\n",
      "Epoch 30/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9929 - val_loss: 0.0291 - val_recall_19: 0.9884 - 25s/epoch - 243ms/step\n",
      "Epoch 31/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9929 - val_loss: 0.0291 - val_recall_19: 0.9884 - 25s/epoch - 243ms/step\n",
      "Epoch 32/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9929 - val_loss: 0.0291 - val_recall_19: 0.9884 - 25s/epoch - 243ms/step\n",
      "Epoch 33/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9929 - val_loss: 0.0291 - val_recall_19: 0.9884 - 26s/epoch - 243ms/step\n",
      "Epoch 34/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 25s/epoch - 243ms/step\n",
      "Epoch 35/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 26s/epoch - 243ms/step\n",
      "Epoch 36/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 25s/epoch - 243ms/step\n",
      "Epoch 37/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 26s/epoch - 243ms/step\n",
      "Epoch 38/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 26s/epoch - 243ms/step\n",
      "Epoch 39/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 25s/epoch - 243ms/step\n",
      "Epoch 40/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9883 - 26s/epoch - 243ms/step\n",
      "Epoch 41/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9883 - 26s/epoch - 243ms/step\n",
      "Epoch 42/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9883 - 26s/epoch - 243ms/step\n",
      "Epoch 43/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9883 - 26s/epoch - 243ms/step\n",
      "Epoch 44/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9883 - 26s/epoch - 243ms/step\n",
      "Epoch 45/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9883 - 25s/epoch - 243ms/step\n",
      "Epoch 46/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9883 - 26s/epoch - 243ms/step\n",
      "Epoch 47/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9883 - 26s/epoch - 243ms/step\n",
      "Epoch 48/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9883 - 26s/epoch - 244ms/step\n",
      "Epoch 49/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9883 - 26s/epoch - 243ms/step\n",
      "Epoch 50/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9883 - 26s/epoch - 243ms/step\n",
      "Epoch 51/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9883 - 25s/epoch - 243ms/step\n",
      "Epoch 52/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9883 - 25s/epoch - 243ms/step\n",
      "Epoch 53/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9883 - 25s/epoch - 243ms/step\n",
      "Epoch 54/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9883 - 25s/epoch - 243ms/step\n",
      "Epoch 55/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9883 - 25s/epoch - 243ms/step\n",
      "Epoch 56/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9883 - 26s/epoch - 243ms/step\n",
      "Epoch 57/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9883 - 25s/epoch - 243ms/step\n",
      "Epoch 58/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9883 - 25s/epoch - 243ms/step\n",
      "Epoch 59/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9883 - 25s/epoch - 243ms/step\n",
      "Epoch 60/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9883 - 26s/epoch - 243ms/step\n",
      "Epoch 61/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9883 - 25s/epoch - 243ms/step\n",
      "Epoch 62/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9883 - 26s/epoch - 243ms/step\n",
      "Epoch 63/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9883 - 26s/epoch - 243ms/step\n",
      "Epoch 64/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9883 - 26s/epoch - 243ms/step\n",
      "Epoch 65/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9883 - 26s/epoch - 243ms/step\n",
      "Epoch 66/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9883 - 26s/epoch - 243ms/step\n",
      "Epoch 67/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9883 - 26s/epoch - 243ms/step\n",
      "Epoch 68/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 26s/epoch - 243ms/step\n",
      "Epoch 69/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 25s/epoch - 243ms/step\n",
      "Epoch 70/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 26s/epoch - 243ms/step\n",
      "Epoch 71/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 25s/epoch - 243ms/step\n",
      "Epoch 72/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 26s/epoch - 243ms/step\n",
      "Epoch 73/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 26s/epoch - 243ms/step\n",
      "Epoch 74/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 26s/epoch - 244ms/step\n",
      "Epoch 75/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 26s/epoch - 243ms/step\n",
      "Epoch 76/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 26s/epoch - 243ms/step\n",
      "Epoch 77/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 26s/epoch - 243ms/step\n",
      "Epoch 78/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 26s/epoch - 244ms/step\n",
      "Epoch 79/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 26s/epoch - 244ms/step\n",
      "Epoch 80/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 26s/epoch - 244ms/step\n",
      "Epoch 81/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 26s/epoch - 244ms/step\n",
      "Epoch 82/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 26s/epoch - 244ms/step\n",
      "Epoch 83/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 26s/epoch - 244ms/step\n",
      "Epoch 84/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 26s/epoch - 244ms/step\n",
      "Epoch 85/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 26s/epoch - 243ms/step\n",
      "Epoch 86/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 26s/epoch - 243ms/step\n",
      "Epoch 87/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 26s/epoch - 243ms/step\n",
      "Epoch 88/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 26s/epoch - 243ms/step\n",
      "Epoch 89/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 26s/epoch - 243ms/step\n",
      "Epoch 90/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 26s/epoch - 243ms/step\n",
      "Epoch 91/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 26s/epoch - 244ms/step\n",
      "Epoch 92/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 26s/epoch - 244ms/step\n",
      "Epoch 93/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 26s/epoch - 244ms/step\n",
      "Epoch 94/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 26s/epoch - 244ms/step\n",
      "Epoch 95/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 26s/epoch - 244ms/step\n",
      "Epoch 96/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 26s/epoch - 244ms/step\n",
      "Epoch 97/100\n",
      "105/105 - 26s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 26s/epoch - 243ms/step\n",
      "Epoch 98/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 25s/epoch - 243ms/step\n",
      "Epoch 99/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 25s/epoch - 243ms/step\n",
      "Epoch 100/100\n",
      "105/105 - 25s - loss: 0.0172 - recall_19: 0.9930 - val_loss: 0.0291 - val_recall_19: 0.9884 - 25s/epoch - 243ms/step\n"
     ]
    }
   ],
   "source": [
    "history_best = best_model.fit(X_train, Y_train, epochs=100, validation_split = 0.01, batch_size=40000, verbose = 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_model.save(f\"model_best.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history_best' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_5096/2446823870.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mplt\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mplot\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhistory_best\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhistory\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"loss\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'history_best' is not defined"
     ]
    }
   ],
   "source": [
    "plt.plot(history_best.history[\"loss\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 4s 236ms/step\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(\"test_dataset_test.csv\")\n",
    "X_test = get_test_dataset_x(test[test.columns[:]], norm, pca)\n",
    "Y_test = best_model.predict(X_test, batch_size = 100000, verbose=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "classif = encod_y.inverse_transform(Y_test)\n",
    "id = test[\"id\"].to_numpy()\n",
    "res = list(zip(id,classif))\n",
    "out = pd.DataFrame(res, columns=[\"id\", \"Class\"])\n",
    "out.to_csv(f\"result_13.csv\", index=False)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}